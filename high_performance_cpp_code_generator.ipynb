{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "108c7ffc-54c7-4a98-bd07-f4d2206f04f8",
   "metadata": {},
   "source": [
    "# C ++ Code Generator\n",
    "\n",
    "The requirement: use Frontier model and Open Source model to generate high performance C++ code from Python code\n",
    "\n",
    "To replicate this, you'll need to set up a HuggingFace endpoint. It's simple to do, and it's quite satisfying to see the results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bdd69ec2-7513-4d72-8bf8-58c8133d67ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import os\n",
    "import io\n",
    "import sys\n",
    "import json\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import google.generativeai\n",
    "import anthropic\n",
    "from IPython.display import Markdown, display, update_display\n",
    "import gradio as gr\n",
    "import subprocess\n",
    "from huggingface_hub import login, InferenceClient\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f67295e-a4ad-4de4-8c93-00828f88f2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# environment\n",
    "\n",
    "load_dotenv(override=True)\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY', 'your-key-if-not-using-env')\n",
    "os.environ['GOOGLE_API_KEY'] = os.getenv('GOOGLE_API_KEY', 'your-key-if-not-using-env')\n",
    "os.environ['GROQ_API_KEY'] = os.getenv('GROQ_API_KEY', 'your-key-if-not-using-env')\n",
    "# To get your HuggingFace token, simply create your account on the HuggingFace website and create it.\n",
    "os.environ['HF_TOKEN'] = os.getenv('HF_TOKEN', 'your-key-if-not-using-env')\n",
    "groq_api_key = os.getenv('GROQ_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b514ef37-e2ed-4d38-98bc-b9ff901101ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize\n",
    "\n",
    "openai = OpenAI()\n",
    "google.generativeai.configure()\n",
    "OPENAI_MODEL = \"gpt-4o\"\n",
    "GOOGLE_MODEL = \"gemini-2.0-flash-exp\"\n",
    "GROQ_MODEL = \"llama-3.3-70b-versatile\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a97901e0-8c5d-45ed-93e7-49dc5d14de4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"You are an assistant that reimplements Python code in high performance C++ for PC under Windows. \"\n",
    "system_message += \"Respond only with C++ code; use comments sparingly and do not provide any explanation other than occasional comments. \"\n",
    "system_message += \"The C++ response needs to produce an identical output in the fastest possible time. Keep implementations of random number generators identical so that results match exactly.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a5463be-a61e-4446-b6da-b6813291a5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_prompt_for(python):\n",
    "    user_prompt = \"Rewrite this Python code in C++ with the fastest possible implementation that produces identical output in the least time. \"\n",
    "    user_prompt += \"Respond only with C++ code; do not explain your work other than a few comments. \"\n",
    "    user_prompt += \"Pay attention to number types to ensure no int overflows. Remember to #include all necessary C++ packages such as iomanip.\\n\\n\"\n",
    "    user_prompt += python\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "49f7eb88-1825-41da-8639-e2bfc2b266dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def messages_for(python):\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "        {\"role\": \"user\", \"content\": user_prompt_for(python)}\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "84cebb2a-e00e-48a3-ad85-87c849e101ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write to a file called optimized.cpp\n",
    "\n",
    "def write_output(cpp):\n",
    "    code = cpp.replace(\"```cpp\",\"\").replace(\"```\",\"\")\n",
    "    with open(\"optimized.cpp\", \"w\") as f:\n",
    "        f.write(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "65c4a6fe-b3ec-49f5-9a56-8f209a7117a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pi = \"\"\"\n",
    "import time\n",
    "\n",
    "def calculate(iterations, param1, param2):\n",
    "    result = 1.0\n",
    "    for i in range(1, iterations+1):\n",
    "        j = i * param1 - param2\n",
    "        result -= (1/j)\n",
    "        j = i * param1 + param2\n",
    "        result += (1/j)\n",
    "    return result\n",
    "\n",
    "start_time = time.time()\n",
    "result = calculate(100_000_000, 4, 1) * 4\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"Result: {result:.12f}\")\n",
    "print(f\"Execution Time: {(end_time - start_time):.6f} seconds\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "edb0eb25-1cf8-4fe9-90cc-9158728467a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: 3.141592658589\n",
      "Execution Time: 33.201466 seconds\n"
     ]
    }
   ],
   "source": [
    "exec(pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "79c43dba-9614-4eba-a6c7-1db456e24190",
   "metadata": {},
   "outputs": [],
   "source": [
    "python_hard = \"\"\"# Be careful to support large number sizes\n",
    "\n",
    "def lcg(seed, a=1664525, c=1013904223, m=2**32):\n",
    "    value = seed\n",
    "    while True:\n",
    "        value = (a * value + c) % m\n",
    "        yield value\n",
    "        \n",
    "def max_subarray_sum(n, seed, min_val, max_val):\n",
    "    lcg_gen = lcg(seed)\n",
    "    random_numbers = [next(lcg_gen) % (max_val - min_val + 1) + min_val for _ in range(n)]\n",
    "    max_sum = float('-inf')\n",
    "    for i in range(n):\n",
    "        current_sum = 0\n",
    "        for j in range(i, n):\n",
    "            current_sum += random_numbers[j]\n",
    "            if current_sum > max_sum:\n",
    "                max_sum = current_sum\n",
    "    return max_sum\n",
    "\n",
    "def total_max_subarray_sum(n, initial_seed, min_val, max_val):\n",
    "    total_sum = 0\n",
    "    lcg_gen = lcg(initial_seed)\n",
    "    for _ in range(20):\n",
    "        seed = next(lcg_gen)\n",
    "        total_sum += max_subarray_sum(n, seed, min_val, max_val)\n",
    "    return total_sum\n",
    "\n",
    "# Parameters\n",
    "n = 10000         # Number of random numbers\n",
    "initial_seed = 42 # Initial seed for the LCG\n",
    "min_val = -10     # Minimum value of random numbers\n",
    "max_val = 10      # Maximum value of random numbers\n",
    "\n",
    "# Timing the function\n",
    "import time\n",
    "start_time = time.time()\n",
    "result = total_max_subarray_sum(n, initial_seed, min_val, max_val)\n",
    "end_time = time.time()\n",
    "\n",
    "print(\"Total Maximum Subarray Sum (20 runs):\", result)\n",
    "print(\"Execution Time: {:.6f} seconds\".format(end_time - start_time))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b841277c-de03-4f56-b01a-c3c3222d952a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Maximum Subarray Sum (20 runs): 10980\n",
      "Execution Time: 98.249988 seconds\n"
     ]
    }
   ],
   "source": [
    "exec(python_hard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6a069c16-4f43-445b-b55e-cfcf5a27543e",
   "metadata": {},
   "outputs": [],
   "source": [
    "high_k_produit = \"\"\"# Génère une très longue chaîne de chiffres pseudo-aléatoires\n",
    "def generate_large_digit_string(length, seed):\n",
    "    import random\n",
    "    random.seed(seed)\n",
    "    return ''.join(str(random.randint(0, 9)) for _ in range(length))\n",
    "\n",
    "# Calcule le plus grand produit de k chiffres consécutifs\n",
    "def max_product_in_series(series, k):\n",
    "    max_product = 0\n",
    "    current_product = 1\n",
    "    zero_count = 0\n",
    "\n",
    "    # Initialisation\n",
    "    for i in range(k):\n",
    "        digit = int(series[i])\n",
    "        if digit == 0:\n",
    "            zero_count += 1\n",
    "        else:\n",
    "            current_product *= digit\n",
    "\n",
    "    if zero_count == 0:\n",
    "        max_product = current_product\n",
    "\n",
    "    # Parcours de la série\n",
    "    for i in range(k, len(series)):\n",
    "        exiting = int(series[i - k])\n",
    "        entering = int(series[i])\n",
    "\n",
    "        if exiting == 0:\n",
    "            zero_count -= 1\n",
    "        else:\n",
    "            current_product //= exiting\n",
    "\n",
    "        if entering == 0:\n",
    "            zero_count += 1\n",
    "        else:\n",
    "            current_product *= entering\n",
    "\n",
    "        if zero_count == 0 and current_product > max_product:\n",
    "            max_product = current_product\n",
    "\n",
    "    return max_product\n",
    "\n",
    "# Paramètres\n",
    "length = 1000000     # Longueur de la chaîne (1 million de chiffres)\n",
    "k = 13               # Nombre de chiffres consécutifs\n",
    "seed = 42            # Graine pour la reproductibilité\n",
    "\n",
    "import time\n",
    "print(\"Génération d'une grande série numérique...\")\n",
    "start = time.time()\n",
    "series = generate_large_digit_string(length, seed)\n",
    "print(\"Série générée en {:.3f} s\".format(time.time() - start))\n",
    "\n",
    "print(f\"Recherche du plus grand produit de {k} chiffres consécutifs...\")\n",
    "start = time.time()\n",
    "result = max_product_in_series(series, k)\n",
    "print(\"Produit maximum trouvé :\", result)\n",
    "print(\"Temps de calcul : {:.6f} secondes\".format(time.time() - start))\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6aad63e3-c87b-4ea1-8841-811a005721be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Génération d'une grande série numérique...\n",
      "Série générée en 2.616 s\n",
      "Recherche du plus grand produit de 13 chiffres consécutifs...\n",
      "Produit maximum trouvé : 258096513024\n",
      "Temps de calcul : 1.316650 secondes\n"
     ]
    }
   ],
   "source": [
    "exec(high_k_produit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "428984ee-2905-4cb9-b8ce-16f43829d27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## OpenAI model\n",
    "def stream_gpt(python):    \n",
    "    stream = openai.chat.completions.create(model=OPENAI_MODEL, messages=messages_for(python), stream=True)\n",
    "    reply = \"\"\n",
    "    for chunk in stream:\n",
    "        fragment = chunk.choices[0].delta.content or \"\"\n",
    "        reply += fragment\n",
    "        yield reply.replace('```cpp\\n','').replace('```','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dc4c3dcb-c104-48ce-a293-edca059b3cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Gemini model\n",
    "def stream_gemini(python):\n",
    "    gemini = google.generativeai.GenerativeModel(\n",
    "        model_name=GOOGLE_MODEL,\n",
    "        system_instruction=system_message\n",
    "    )\n",
    "    result = gemini.generate_content(user_prompt_for(python), stream=True)\n",
    "    reply = \"\"\n",
    "    for chuck in result:\n",
    "        text = chuck.text\n",
    "        reply += text or \"\"\n",
    "        yield reply.replace('```cpp\\n','').replace('```','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7e96c808-0286-4e0e-aa20-69ec2d7b4f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "##  Groq model\n",
    "def stream_groq(python):\n",
    "    groq = OpenAI(api_key = groq_api_key, base_url=\"https://api.groq.com/openai/v1\")\n",
    "    stream = groq.chat.completions.create(\n",
    "        model= GROQ_MODEL,\n",
    "        messages = messages_for(python),\n",
    "        stream=True\n",
    "    )\n",
    "    reply = \"\"\n",
    "    for chunk in stream:\n",
    "        reply += chunk.choices[0].delta.content or \"\"\n",
    "        yield result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "60167c8f-388a-409a-96a4-435bc3d0c103",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
     ]
    }
   ],
   "source": [
    "# Setting environment to use HuggingFace open source models\n",
    "hf_token = os.environ['HF_TOKEN']\n",
    "login(hf_token, add_to_git_credential=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8dbe3b3e-4d20-4ae1-916e-0fdf8a295495",
   "metadata": {},
   "outputs": [],
   "source": [
    "code_qwen = \"Qwen/CodeQwen1.5-7B-Chat\"\n",
    "star_coder = \"bigcode/starcoder2-7b\"\n",
    "\n",
    "#code_gemma = \"google/codegemma-7b-it\"\n",
    "\n",
    "## The endpoint links\n",
    "## The endpoint must be obtained from HuggingFace and should be activated before running.\n",
    "CODE_QWEN_URL = \"https://omifz2mbs0p1jtzw.us-east4.gcp.endpoints.huggingface.cloud\"\n",
    "CODE_STAR_CDOE_URL = \"https://vv7455wo30sk1vkc.us-east4.gcp.endpoints.huggingface.cloud\"\n",
    "#CODE_GEMMA_URL = \"https://c5hggiyqachmgnqg.us-east-1.aws.endpoints.huggingface.cloud\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4db451a4-f14f-42dc-9197-9c6a23d63b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using model via endpoint\n",
    "tokenizer = AutoTokenizer.from_pretrained(code_qwen)\n",
    "messages = messages_for(pi)\n",
    "text = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "01881e2a-db32-428b-bda4-4aa047c5a290",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|im_start|>system\\nYou are an assistant that reimplements Python code in high performance C++ for PC under Windows. Respond only with C++ code; use comments sparingly and do not provide any explanation other than occasional comments. The C++ response needs to produce an identical output in the fastest possible time. Keep implementations of random number generators identical so that results match exactly.<|im_end|>\\n<|im_start|>user\\nRewrite this Python code in C++ with the fastest possible implementation that produces identical output in the least time. Respond only with C++ code; do not explain your work other than a few comments. Pay attention to number types to ensure no int overflows. Remember to #include all necessary C++ packages such as iomanip.\\n\\n\\nimport time\\n\\ndef calculate(iterations, param1, param2):\\n    result = 1.0\\n    for i in range(1, iterations+1):\\n        j = i * param1 - param2\\n        result -= (1/j)\\n        j = i * param1 + param2\\n        result += (1/j)\\n    return result\\n\\nstart_time = time.time()\\nresult = calculate(100_000_000, 4, 1) * 4\\nend_time = time.time()\\n\\nprint(f\"Result: {result:.12f}\")\\nprint(f\"Execution Time: {(end_time - start_time):.6f} seconds\")\\n<|im_end|>\\n<|im_start|>assistant\\n'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120ebabb-b3c8-4f30-a050-187087868a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = InferenceClient(CODE_QWEN_URL, token=hf_token)\n",
    "stream = client.text_generation(text, stream=True, details=True, max_new_tokens=3000)\n",
    "result = \"\"\n",
    "for r in stream:\n",
    "    result += r.token.text\n",
    "    print(result, end = \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9105bb05-1a19-40b9-bf75-145c844457c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## CodeQwen model\n",
    "def stream_code_qwen(python):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(code_qwen)\n",
    "    messages = messages_for(python)\n",
    "    text = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "    client = InferenceClient(CODE_QWEN_URL, token=hf_token)\n",
    "    stream = client.text_generation(text, stream=True, details=True, max_new_tokens=3000)\n",
    "    result = \"\"\n",
    "    for r in stream:\n",
    "        result += r.token.text\n",
    "        yield result    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "eceeab2f-eb29-459c-a271-9758aa4ca771",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Starcoder model\n",
    "def stream_star_coder(python):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(star_coder)\n",
    "    messages = messages_for(python)\n",
    "    text = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "    client = InferenceClient(CODE_STAR_CDOE_URL, token=hf_token)\n",
    "    stream = client.text_generation(text, stream=True, details=True, max_new_tokens=3000)\n",
    "    result = \"\"\n",
    "    for r in stream:\n",
    "        result += r.token.text\n",
    "        yield result    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "dd10faff-b9be-47d1-816e-6575ebdd4781",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize(python, model):\n",
    "    if model==\"GPT\":\n",
    "        result = stream_gpt(python)\n",
    "    elif model==\"Gemini\":\n",
    "        result = stream_gemini(python)\n",
    "    elif model == \"Groq\":\n",
    "        result = stream_groq(python)\n",
    "    elif model==\"CodeQwen\":\n",
    "        result = stream_code_qwen(python)\n",
    "    elif model == \"Star coder\":\n",
    "        result = stream_star_coder(python)\n",
    "    else:\n",
    "        raise ValueError(\"Unknown model\")\n",
    "    for stream_so_far in result:\n",
    "        yield stream_so_far    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "40e5e687-0074-4c30-8d9d-a01cbef89927",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_sample_program(sample_program):\n",
    "    if sample_program==\"pi\":\n",
    "        return pi\n",
    "    elif sample_program==\"python_hard\":\n",
    "        return python_hard\n",
    "    elif sample_program==\"high_k_produit\":\n",
    "        return high_k_produit\n",
    "    else:\n",
    "        return \"Type your Python program here\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "05daa9b0-2fdc-4c76-a139-b4939b3b870b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check compiler on the all kind of system \n",
    "# These function return the compiler of the code\n",
    "import platform\n",
    "\n",
    "VISUAL_STUDIO_2022_TOOLS = \"C:\\\\Program Files\\\\Microsoft Visual Studio\\\\2022\\\\Community\\\\Common7\\Tools\\\\VsDevCmd.bat\"\n",
    "VISUAL_STUDIO_2019_TOOLS = \"C:\\\\Program Files (x86)\\\\Microsoft Visual Studio\\\\2019\\\\BuildTools\\\\Common7\\\\Tools\\\\VsDevCmd.bat\"\n",
    "\n",
    "simple_cpp = \"\"\"\n",
    "#include <iostream>\n",
    "\n",
    "int main() {\n",
    "    std::cout << \"Hello\";\n",
    "    return 0;\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "def run_cmd(command_to_run):\n",
    "    try:\n",
    "        run_result = subprocess.run(command_to_run, check=True, text=True, capture_output=True)\n",
    "        return run_result.stdout if run_result.stdout else \"SUCCESS\"\n",
    "    except:\n",
    "        return \"\"\n",
    "\n",
    "def c_compiler_cmd(filename_base):\n",
    "    my_platform = platform.system()\n",
    "    my_compiler = []\n",
    "\n",
    "    try:\n",
    "        with open(\"simple.cpp\", \"w\") as f:\n",
    "            f.write(simple_cpp)\n",
    "            \n",
    "        if my_platform == \"Windows\":\n",
    "            if os.path.isfile(VISUAL_STUDIO_2022_TOOLS):\n",
    "                if os.path.isfile(\"./simple.exe\"):\n",
    "                    os.remove(\"./simple.exe\")\n",
    "                compile_cmd = [\"cmd\", \"/c\", VISUAL_STUDIO_2022_TOOLS, \"&\", \"cl\", \"simple.cpp\"]\n",
    "                if run_cmd(compile_cmd):\n",
    "                    if run_cmd([\"./simple.exe\"]) == \"Hello\":\n",
    "                        my_compiler = [\"Windows\", \"Visual Studio 2022\", [\"cmd\", \"/c\", VISUAL_STUDIO_2022_TOOLS, \"&\", \"cl\", f\"{filename_base}.cpp\"]]\n",
    "        \n",
    "            if not my_compiler:\n",
    "                if os.path.isfile(VISUAL_STUDIO_2019_TOOLS):\n",
    "                    if os.path.isfile(\"./simple.exe\"):\n",
    "                        os.remove(\"./simple.exe\")\n",
    "                    compile_cmd = [\"cmd\", \"/c\", VISUAL_STUDIO_2019_TOOLS, \"&\", \"cl\", \"simple.cpp\"]\n",
    "                    if run_cmd(compile_cmd):\n",
    "                        if run_cmd([\"./simple.exe\"]) == \"Hello\":\n",
    "                            my_compiler = [\"Windows\", \"Visual Studio 2019\", [\"cmd\", \"/c\", VISUAL_STUDIO_2019_TOOLS, \"&\", \"cl\", f\"{filename_base}.cpp\"]]\n",
    "    \n",
    "            if not my_compiler:\n",
    "                my_compiler=[my_platform, \"Unavailable\", []]\n",
    "                \n",
    "        elif my_platform == \"Linux\":\n",
    "            if os.path.isfile(\"./simple\"):\n",
    "                os.remove(\"./simple\")\n",
    "            compile_cmd = [\"g++\", \"simple.cpp\", \"-o\", \"simple\"]\n",
    "            if run_cmd(compile_cmd):\n",
    "                if run_cmd([\"./simple\"]) == \"Hello\":\n",
    "                    my_compiler = [\"Linux\", \"GCC (g++)\", [\"g++\", f\"{filename_base}.cpp\", \"-o\", f\"{filename_base}\" ]]\n",
    "    \n",
    "            if not my_compiler:\n",
    "                if os.path.isfile(\"./simple\"):\n",
    "                    os.remove(\"./simple\")\n",
    "                compile_cmd = [\"clang++\", \"simple.cpp\", \"-o\", \"simple\"]\n",
    "                if run_cmd(compile_cmd):\n",
    "                    if run_cmd([\"./simple\"]) == \"Hello\":\n",
    "                        my_compiler = [\"Linux\", \"Clang++\", [\"clang++\", f\"{filename_base}.cpp\", \"-o\", f\"{filename_base}\"]]\n",
    "        \n",
    "            if not my_compiler:\n",
    "                my_compiler=[my_platform, \"Unavailable\", []]\n",
    "    \n",
    "        elif my_platform == \"Darwin\":\n",
    "            if os.path.isfile(\"./simple\"):\n",
    "                os.remove(\"./simple\")\n",
    "            compile_cmd = [\"clang++\", \"-Ofast\", \"-std=c++17\", \"-march=armv8.5-a\", \"-mtune=apple-m1\", \"-mcpu=apple-m1\", \"-o\", \"simple\", \"simple.cpp\"]\n",
    "            if run_cmd(compile_cmd):\n",
    "                if run_cmd([\"./simple\"]) == \"Hello\":\n",
    "                    my_compiler = [\"Macintosh\", \"Clang++\", [\"clang++\", \"-Ofast\", \"-std=c++17\", \"-march=armv8.5-a\", \"-mtune=apple-m1\", \"-mcpu=apple-m1\", \"-o\", f\"{filename_base}\", f\"{filename_base}.cpp\"]]\n",
    "    \n",
    "            if not my_compiler:\n",
    "                my_compiler=[my_platform, \"Unavailable\", []]\n",
    "    except:\n",
    "        my_compiler=[my_platform, \"Unavailable\", []]\n",
    "        \n",
    "    if my_compiler:\n",
    "        return my_compiler\n",
    "    else:\n",
    "        return [\"Unknown\", \"Unavailable\", []]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "85dd714f-6053-459d-a4a6-82ef9a1c1cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "compiler_cmd = c_compiler_cmd(\"optimized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c9eb1e46-8fd4-429f-8e53-cae7a6555c8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Windows',\n",
       " 'Visual Studio 2019',\n",
       " ['cmd',\n",
       "  '/c',\n",
       "  'C:\\\\Program Files (x86)\\\\Microsoft Visual Studio\\\\2019\\\\BuildTools\\\\Common7\\\\Tools\\\\VsDevCmd.bat',\n",
       "  '&',\n",
       "  'cl',\n",
       "  'optimized.cpp']]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compiler_cmd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b14f583a-381d-421c-9424-9cb93faeb30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "VISUAL_STUDIO_2019_TOOLS = \"C:\\\\Program Files (x86)\\\\Microsoft Visual Studio\\\\2019\\\\BuildTools\\\\Common7\\\\Tools\\\\VsDevCmd.bat\"\n",
    "\n",
    "def run_cpp(cpp):\n",
    "    write_output(cpp)\n",
    "    if os.path.isfile(VISUAL_STUDIO_2019_TOOLS):\n",
    "        if os.path.isfile(\"./optimized.exe\"):\n",
    "            os.remove(\"./optimized.exe\")\n",
    "        compile_cmd = [\"cmd\", \"/c\", VISUAL_STUDIO_2019_TOOLS, \"&\", \"cl\", \"optimized.cpp\"]\n",
    "        if run_cmd(compile_cmd):\n",
    "            result = run_cmd([\"./optimized.exe\"])\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5371bd57-a914-447e-bf0f-d801592384c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"**********************************************************************\\n** Visual Studio 2019 Developer Command Prompt v16.11.45\\n** Copyright (c) 2021 Microsoft Corporation\\n**********************************************************************\\noptimized.cpp\\nC:\\\\Program Files (x86)\\\\Microsoft Visual Studio\\\\2019\\\\BuildTools\\\\VC\\\\Tools\\\\MSVC\\\\14.29.30133\\\\include\\\\ostream(410): warning C4530: Gestionnaire d'exceptions C++ utilis‚, mais les s‚mantiques de d‚roulement n'ont pas ‚t‚ activ‚es. Sp‚cifiez /EHsc\\nC:\\\\Program Files (x86)\\\\Microsoft Visual Studio\\\\2019\\\\BuildTools\\\\VC\\\\Tools\\\\MSVC\\\\14.29.30133\\\\include\\\\ostream(403): note: pendant la compilation de la fonction membre classe modŠle 'std::basic_ostream<char,std::char_traits<char>> &std::basic_ostream<char,std::char_traits<char>>::operator <<(double)'\\noptimized.cpp(24): note: voir la r‚f‚rence … l'instanciation de la fonction modŠle 'std::basic_ostream<char,std::char_traits<char>> &std::basic_ostream<char,std::char_traits<char>>::operator <<(double)' en cours de compilation\\noptimized.cpp(23): note: voir la r‚f‚rence … l'instanciation classe modŠle 'std::basic_ostream<char,std::char_traits<char>>' en cours de compilation\\nMicrosoft (R) Incremental Linker Version 14.29.30159.0\\nCopyright (C) Microsoft Corporation.  All rights reserved.\\n\\n/out:optimized.exe \\noptimized.obj \\n\""
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compile_cmd = [\"cmd\", \"/c\", VISUAL_STUDIO_2019_TOOLS, \"&\", \"cl\", \"optimized.cpp\"]\n",
    "run_cmd(compile_cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "daf6deb6-428e-48ca-a037-cd08e7fa74b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_python(code):\n",
    "    try:\n",
    "        output = io.StringIO()\n",
    "        sys.stdout = output\n",
    "        exec(code)\n",
    "    finally:\n",
    "        sys.stdout = sys.__stdout__\n",
    "    return output.getvalue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c073ab7-67ed-481a-b4a8-f4d00ea6146e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "run_cpp(python_hard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "53f1f215-58ad-49d1-8683-af6b97c7c123",
   "metadata": {},
   "outputs": [],
   "source": [
    "css = \"\"\"\n",
    ".python {background-color: #306998;}\n",
    ".cpp {background-color: #050;}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "311d2559-4f23-4021-83fa-081a342253db",
   "metadata": {},
   "outputs": [],
   "source": [
    "with gr.Blocks(css=css) as ui:\n",
    "    gr.Markdown(\"## Convert code from Python to C++\")\n",
    "    with gr.Row():\n",
    "        python = gr.Textbox(label=\"Python code:\", value=python_hard, lines=10)\n",
    "        cpp = gr.Textbox(label=\"C++ code:\", lines=10)\n",
    "    with gr.Row():\n",
    "        with gr.Column():\n",
    "            sample_program = gr.Radio([\"pi\", \"python_hard\", \"high_k_produit\"], label=\"Sample program\", value=\"python_hard\")\n",
    "            model = gr.Dropdown([\"GPT\", \"Gemini\", \"Groq\", \"CodeQwen\", \"Star coder\"], label=\"Select model\", value=\"GPT\")\n",
    "        with gr.Column():\n",
    "            architecture = gr.Radio([compiler_cmd[0]], label=\"Architecture\", interactive=False, value=compiler_cmd[0])\n",
    "            compiler = gr.Radio([compiler_cmd[1]], label=\"Compiler\", interactive=False, value=compiler_cmd[1])\n",
    "    with gr.Row():\n",
    "        convert = gr.Button(\"Convert code\")\n",
    "    with gr.Row():\n",
    "        python_run = gr.Button(\"Run Python\")\n",
    "        if not compiler_cmd[1] == \"Unavailable\":\n",
    "            cpp_run = gr.Button(\"Run C++\")\n",
    "        else:\n",
    "            cpp_run = gr.Button(\"No compiler to run C++\", interactive=False)\n",
    "    with gr.Row():\n",
    "        python_out = gr.TextArea(label=\"Python result:\", elem_classes=[\"python\"])\n",
    "        cpp_out = gr.TextArea(label=\"C++ result:\", elem_classes=[\"cpp\"])\n",
    "\n",
    "    sample_program.change(select_sample_program, inputs=[sample_program], outputs=[python])\n",
    "    convert.click(optimize, inputs=[python, model], outputs=[cpp])\n",
    "    python_run.click(execute_python, inputs=[python], outputs=[python_out])\n",
    "    cpp_run.click(run_cpp, inputs=[cpp], outputs=[cpp_out])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ff69a71e-5413-4c3c-a1c9-79c8891c1d4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7868/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ui.launch() #inbrowser=True"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
