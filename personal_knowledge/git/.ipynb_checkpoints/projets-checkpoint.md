# Projets

## Agent LinkedIn : G√©n√©ration des postes pour Linkedin 

Cet agent intelligent automatise la cr√©ation de posts LinkedIn en utilisant l'IA pour g√©n√©rer du contenu pertinent et engageant. Il utilise plusieurs mod√®les d'IA (OpenAI, Groq, et Gemini) pour g√©n√©rer des posts de qualit√©.

## Fonctionnalit√©s

- üîê Authentification s√©curis√©e avec LinkedIn
- üîç Analyse des publications r√©centes bas√©e sur un th√®me
- üß† Suggestions de sujets personnalis√©s
- ‚úçÔ∏è G√©n√©ration de posts avec diff√©rents mod√®les d'IA :
  - OpenAI (GPT-4.1-mini)
  - Groq (Llama-3.3-70b-versatile)
  - Google Gemini (Gemini-2.0-flash)

## Pr√©requis

- Python 3.8 ou sup√©rieur
- Compte LinkedIn
- Cl√©s API pour :
  - OpenAI
  - Groq
  - Google Gemini

## Installation

1. Clonez ce d√©p√¥t :
```bash
git clone [URL_DU_REPO]
cd [NOM_DU_DOSSIER]
```

2. Installez les d√©pendances :
```bash
pip install linkedin-api
pip install openai
pip install python-dotenv
```

3. Configurez les variables d'environnement :
   - Cr√©ez un fichier `.env` √† la racine du projet
   - Copiez le contenu suivant et remplissez les valeurs :
   ```
   LINKEDIN_EMAIL=your_email@example.com
   LINKEDIN_PASSWORD=your_password
   OPENAI_API_KEY=your_openai_api_key
   GROQ_API_KEY=your_groq_api_key
   GOOGLE_API_KEY=your_google_api_key
   ```

## Utilisation

1. Lancez l'agent :
```bash
python linkedin_agent.py
```

2. Suivez les instructions √† l'√©cran pour :
   - Vous authentifier sur LinkedIn
   - Entrer un th√®me pour l'analyse des publications
   - Choisir parmi les suggestions de sujets g√©n√©r√©es
   - G√©n√©rer des posts avec diff√©rents mod√®les d'IA

## S√©curit√©

- Ne partagez jamais votre fichier `.env`
- Ne committez pas vos identifiants dans le code
- Utilisez des mots de passe forts
- Gardez vos cl√©s API secr√®tes

## Contribution

Les contributions sont les bienvenues ! N'h√©sitez pas √† :
- Ouvrir une issue pour signaler un bug
- Proposer une pull request pour une am√©lioration
- Partager vos id√©es d'√©volution

## Licence

MIT 

## Agent LinkedIn : G√©n√©ration et Sauvegarde avec Google Docs

Cet agent intelligent automatise la cr√©ation de posts LinkedIn en utilisant l'IA pour g√©n√©rer du contenu pertinent et engageant, et les sauvegarde automatiquement dans Google Docs. Il inclut √©galement la possibilit√© d'une publication assist√©e sur LinkedIn.

## Fonctionnalit√©s

- üîê Authentification s√©curis√©e avec LinkedIn et Google
- üîç Analyse des publications r√©centes
- üß† Suggestions de sujets personnalis√©s
- ‚úçÔ∏è G√©n√©ration de posts avec diff√©rents styles (via OpenAI, Groq, Gemini)
- üìÑ Sauvegarde automatique dans Google Docs
- ‚úÖ Publication assist√©e sur LinkedIn (fonctionnalit√© potentielle / √† venir)

## Pr√©requis

- Python 3.8 ou sup√©rieur
- Compte LinkedIn
- Compte Google avec acc√®s √† Google Docs
- Cl√©s API pour OpenAI, Groq et/ou Google Gemini

## Installation

1. Clonez ce d√©p√¥t :
```bash
git clone [URL_DU_REPO]
cd [NOM_DU_DOSSIER]
```

2. Installez les d√©pendances :
```bash
pip install -r requirements.txt
```

3. Configurez les variables d'environnement :
   - Cr√©ez un fichier `.env` √† la racine du projet
   - Copiez le contenu suivant et remplissez les valeurs :
   ```
   LINKEDIN_EMAIL=your_email@example.com
   LINKEDIN_PASSWORD=your_password
   OPENAI_API_KEY=your_openai_api_key
   GOOGLE_CLIENT_ID=your_google_client_id
   GOOGLE_CLIENT_SECRET=your_google_client_secret
   GOOGLE_API_KEY=your_google_api_key
   GROQ_API_KEY=your_groq_api_key
   ```

4. Configurez l'authentification Google :
   - Allez sur [Google Cloud Console](https://console.cloud.google.com)
   - Cr√©ez un nouveau projet
   - Activez l'API Google Docs
   - Cr√©ez des identifiants OAuth 2.0 (type "Desktop app" ou "Application de bureau")
   - T√©l√©chargez le fichier `credentials.json` et placez-le √† la racine du projet. Ce fichier contient les informations d'identification de votre application.

## Utilisation

1. Lancez l'agent :
```bash
python linkedin_agent_with_docs.py
```

2. Suivez les instructions √† l'√©cran pour :
   - Vous authentifier
   - Choisir un sujet
   - G√©n√©rer et sauvegarder les posts dans Google Docs

## S√©curit√©

- Ne partagez jamais votre fichier `.env`
- Ne committez pas vos identifiants dans le code
- Utilisez des mots de passe forts
- Gardez vos cl√©s API secr√®tes

## Contribution

Les contributions sont les bienvenues ! N'h√©sitez pas √† :
- Ouvrir une issue pour signaler un bug
- Proposer une pull request pour une am√©lioration
- Partager vos id√©es d'√©volution

## Licence

MIT 


## Analyse √©conom√©trique des s√©ries temporelles de rendements d‚ÄôETF : Mod√©lisation GARCH et VAR
## Contexte et objectif du projet
Le projet s'inscrit dans un contexte financier marqu√© par une forte volatilit√© et des dynamiques complexes des march√©s. Il vise √† analyser les s√©ries temporelles des rendements de trois ETF repr√©sentatifs : Amundi MSCI World UCITS ETF - EUR (CW8), Amundi MSCI India UCITS ETF - EUR (CI2) et Amundi FTSE Epra Europe Real Estate UCITS ETF - EUR (EPRE). L'objectif principal est de comprendre les caract√©ristiques propres √† chaque ETF, d'√©tudier la persistance de la volatilit√© et les interactions entre ces actifs, et d'am√©liorer la capacit√© √† anticiper les risques financiers associ√©s. Pour cela, le projet mobilise des mod√®les √©conom√©triques avanc√©s, notamment les mod√®les GARCH et VAR.

## Donn√©es utilis√©es
Les donn√©es utilis√©es sont les s√©ries temporelles des rendements des trois ETF mentionn√©s, cot√©s sur Euronext Paris. Ces ETF couvrent diff√©rents march√©s : actions mondiales (CW8), actions indiennes (CI2) et immobilier cot√© europ√©en (EPRE). Les donn√©es incluent les valeurs historiques des prix, les rendements g√©om√©triques, ainsi que des informations sur la volatilit√© et la corr√©lation entre ces actifs. Les donn√©es proviennent de sources telles qu‚ÄôAmundi.fr et Yahoo Finance.

## M√©thodologie et outils
La m√©thodologie repose sur l‚Äôanalyse √©conom√©trique des s√©ries temporelles. Deux types de mod√®les sont utilis√©s : les mod√®les GARCH(1,1), GARCH multivari√©s (notamment le mod√®le BEKK) pour mod√©liser la volatilit√© conditionnelle et ses dynamiques, et les mod√®les Vectoriels Auto-R√©gressifs (VAR) pour √©tudier les interactions dynamiques entre les rendements des ETF. Le test de causalit√© de Granger est appliqu√© pour d√©tecter les relations de causalit√© entre les s√©ries. La s√©lection de l‚Äôordre du mod√®le VAR est r√©alis√©e √† l‚Äôaide de crit√®res d‚Äôinformation (AIC, BIC, HQIC, FPE). Les outils utilis√©s incluent les langages Python et R.

## Principaux r√©sultats
Les r√©sultats montrent une forte persistance de la volatilit√© pour les ETF CI2 et EPRE, tandis que CW8 pr√©sente une volatilit√© plus stable. La corr√©lation conditionnelle entre les ETF est mod√©r√©e et positive, avec des fluctuations dans le temps. Les tests de causalit√© de Granger r√©v√®lent que les valeurs pass√©es des trois ETF ont un pouvoir pr√©dictif significatif les unes sur les autres, justifiant l‚Äôutilisation conjointe des s√©ries dans les mod√®les VAR. Les fonctions de r√©ponse aux impulsions indiquent que les chocs ont un effet transitoire et principalement localis√© sur la variable d‚Äôorigine, avec une transmission limit√©e entre variables.

## Interpr√©tation et implications
L‚Äô√©tude met en lumi√®re la dynamique sp√©cifique des rendements et de la volatilit√© des ETF, soulignant l‚Äôefficacit√© des mod√®les GARCH(1,1), GARCH et VAR pour capturer ces ph√©nom√®nes. La persistance √©lev√©e de la volatilit√© pour certains ETF sugg√®re un risque accru et une m√©moire longue des chocs pass√©s. La corr√©lation mod√©r√©e entre les ETF ouvre des perspectives de diversification, bien que des phases de turbulence puissent affecter simultan√©ment ces actifs. Ces r√©sultats sont utiles pour optimiser les strat√©gies d‚Äôinvestissement en tenant compte des particularit√©s de chaque ETF et des interactions entre eux.

## Comp√©tences d√©velopp√©es
Ce projet a permis de d√©velopper des comp√©tences avanc√©es en √©conom√©trie des s√©ries temporelles, notamment dans la mod√©lisation GARCH multivari√©e et les mod√®les VAR. Il a renforc√© la ma√Ætrise des tests statistiques comme la causalit√© de Granger, ainsi que l‚Äôinterpr√©tation des fonctions de r√©ponse aux impulsions. L‚Äôutilisation pratique des langages Python et R pour l‚Äôanalyse de donn√©es financi√®res a √©galement √©t√© approfondie, tout comme la capacit√© √† synth√©tiser des r√©sultats complexes pour des applications en finance quantitative.

 <!DOCTYPE html>
<html lang="en">
<body>
    <div class="container">
        <h1>üìä Analyse empirique des ETF (ARIMA) - Finance 2024-2025</h1>
<strong>Contexte et objectif du projet</strong>
        
Ce projet s‚Äôinscrit dans le domaine de la finance empirique et vise √† analyser les propri√©t√©s statistiques et √©conom√©triques des fonds n√©goci√©s en bourse (ETF). L‚Äôobjectif principal est de comprendre la dynamique des rendements de plusieurs ETF, d‚Äô√©valuer leurs caract√©ristiques statistiques, et d‚Äôappliquer des mod√®les √©conom√©triques pour mieux appr√©hender leur comportement temporel.

<strong>Donn√©es utilis√©es</strong>

Les donn√©es utilis√©es sont des s√©ries temporelles quotidiennes des prix de trois ETF : Amundi Index MSCI Emerging Markets UCITS ETF DR (AEME.PA), Amundi MSCI Europe Growth UCITS ETF Acc (CG9.PA), et Amundi MSCI Europe Value Factor UCITS ETF-C (CV9.PA). Ces donn√©es couvrent une p√©riode allant de 2017 √† fin 2024.

<strong>M√©thodologie et outils</strong>

L‚Äôanalyse d√©bute par des statistiques descriptives des rendements g√©om√©triques, accompagn√©es de tests de normalit√© (Jarque-Bera) et d‚Äôanalyse des corr√©lations. Des tests de stationnarit√© (ADF, KPSS) sont ensuite appliqu√©s pour v√©rifier les propri√©t√©s des s√©ries temporelles. La mod√©lisation √©conom√©trique est r√©alis√©e via des mod√®les ARIMA pour capturer les dynamiques des rendements. Enfin, un test de coint√©gration d‚ÄôEngle et Granger est effectu√© pour √©tudier les relations de long terme entre les ETF. Les analyses ont √©t√© conduites √† l‚Äôaide de Gretl.

<strong>Principaux r√©sultats</strong>

Les rendements des ETF pr√©sentent une distribution non normale, avec une forte asym√©trie et un exc√®s de kurtosis, indiquant des √©v√©nements extr√™mes fr√©quents. Les s√©ries de prix ne sont pas stationnaires, mais leurs premi√®res diff√©rences le sont, validant l‚Äôutilisation des mod√®les ARIMA. Le test de coint√©gration r√©v√®le l‚Äôabsence de relation de long terme stable entre les ETF √©tudi√©s.

<strong>Interpr√©tation et implications</strong>

Ces r√©sultats soulignent la complexit√© des dynamiques des actifs financiers et la n√©cessit√© d‚Äôutiliser des mod√®les adapt√©s pour la gestion de portefeuille et l‚Äôanalyse des risques. La non-normalit√© des rendements et l‚Äôabsence de coint√©gration montrent que les strat√©gies d‚Äôinvestissement doivent prendre en compte ces caract√©ristiques pour optimiser la prise de d√©cision.

<strong>Comp√©tences d√©velopp√©es</strong>

Ce travail a permis de renforcer les comp√©tences en analyse statistique, tests √©conom√©triques, mod√©lisation de s√©ries temporelles (mod√®le ARIMA), ainsi qu‚Äôen interpr√©tation des r√©sultats financiers.
</body>
</html>

## Data Visualisation: US-Demography and Italy's 2022 Heatwave
Working as a team of three data scientists, we delivered a two‚Äëpart analytics project that takes raw public data all the way to interactive insights:

1Ô∏è‚É£ U.S. County Demography Explorer
Data¬†: NHGIS population series (2000¬†&¬†2010) for 3,100 counties.

What we built¬†: automated R pipeline (tidyverse¬†+¬†sf) that cleans, joins shapefiles, and feeds a Shiny + Leaflet dashboard. Users click any county to see real‚Äëtime race break‚Äëdowns‚Äîand instantly verify census numbers such as Los¬†Angeles County‚Äôs 9.8¬†M residents.

2Ô∏è‚É£ Climate‚ÄëHealth Impact for Italy, Summer¬†2022
Data¬†: ERA5 land temperatures (2015‚Äë2023) + World¬†Mortality¬†Dataset.

Method¬†: Python pipeline (pandas, xarray, statsmodels) to model expected deaths with week fixed effects, then quantify excess mortality.

Insight¬†: ‚âà¬†26,800 excess deaths linked to the 2022 heatwave; bin‚Äëscatter visuals highlight a sharp mortality jump beyond the 95th‚Äëpercentile temperature.


üîß Tech & Skills
R (tidyverse, Shiny, Leaflet) ‚Ä¢ Python (pandas, xarray, statsmodels, cartopy) ‚Ä¢ CDS & NHGIS APIs.
Spatial data wrangling ‚îÇ time‚Äëseries modelling ‚îÇ interactive dashboards ‚îÇ agile teamwork.

Result¬†: a compact showcase of how we transform gigabytes of climate and demographic data into actionable, recruiter‚Äëready insights. Let‚Äôs talk if you‚Äôre looking for data talent that bridges engineering, analytics and compelling storytelling. üì©

#DataScience #SpatialAnalytics #ClimateRisk #ShinyApps #Python #RStats

## Machine Learning ‚Äì Analyse de sentiment de tweets financiers

Projet universitaire conduit par une √©quipe de 5 √©tudiants.

üîé Pipeline NLP : nettoyage, tokenisation BERT & vectorisation TF‚ÄëIDF.

‚öôÔ∏è 6 mod√®les compar√©s ; BERT en t√™te avec F1‚Äëscore 0,93 (binaire) et 0,75 en multi‚Äëclasse (validation crois√©e 5‚Äëfold) ; BiLSTM 0,88, Random Forest / R√©gression logistique 0,86. ‚Äã

üìà Insights : courbe ROC, importance des tokens (SHAP) et analyse des limites (longueur 512 tokens, co√ªt calcul). ‚Äã

üöÄ Comp√©tences acquises : fine‚Äëtuning Transformers, optimisation hyper‚Äëparam√®tres, validation crois√©e stratifi√©e, visualisation avanc√©e & travail agile.

Pr√©sentation finale le 10 avril 2025 avec rapport 2 pages et d√©mo live. #NLP #Transformers #SentimentAnalysis #MachineLearning

## Analyse des relations entre deux variables via des donn√©es Eurostat un projet en R

Ce projet acad√©mique consiste √† analyser la relation entre deux variables (autres que le PIB et la satisfaction de vie) issues des donn√©es Eurostat. Il est structur√© en quatre √©tapes principales : t√©l√©chargement et importation des donn√©es en R, nettoyage et fusion des ensembles de donn√©es, cr√©ation de statistiques descriptives illustr√©es par des graphiques et tableaux, et enfin mod√©lisation statistique (r√©gression lin√©aire et non lin√©aire) pour examiner la relation entre les deux variables. Le travail finalis√© doit √™tre pr√©sent√© dans un document PDF avec des visualisations pertinentes et des r√©sultats d'analyse, sans inclure le code R ni les donn√©es brutes.

## Predicting high site traffic

This project aims to predict high website traffic for a recipe site by analyzing various data attributes (such as recipe IDs, nutritional values, categories, and serving sizes) to identify recipes likely to attract a large number of visitors. The approach involves data preparation, exploratory analysis, and the development of predictive models‚Äîincluding a linear probability model, logistic regression, and random forest‚Äîimplemented in R. Model performance is assessed using confusion matrices, ROC curves, and AUC, while marginal effects and variable importance guide the site's editorial strategy.

## Data Sampling and Data Communication
This project aims to analyze electoral polls and their results to evaluate their accuracy and understand the challenges they present, particularly in the context of far-right candidates. It consists of three main parts: a theoretical analysis of polls and their methodologies, a data analysis with visualizations to assess poll accuracy, and an interpretation of the results with recommendations to improve their precision. The expected deliverable includes a concise written report and up to three graphs illustrating the key findings.

## Consommation de carburants en France, l'ann√©e 2023

Ce projet vise √† analyser les prix des carburants en France pour l'ann√©e 2023 en utilisant Python. Il comprend plusieurs √©tapes cl√©s : la collecte de donn√©es depuis une source pr√©d√©finie, leur pr√©paration via des transformations sp√©cifiques comme l'extraction des dates ou la cr√©ation d'indices de prix, ainsi que la visualisation des tendances hebdomadaires √† l'aide de biblioth√®ques comme Matplotlib ou Seaborn. En bonus, il propose de cartographier les prix moyens par d√©partement. Enfin, le projet inclut la mod√©lisation pour pr√©voir les prix futurs des carburants, en se concentrant davantage sur la m√©thodologie que sur l'optimisation du mod√®le. Le livrable attendu est un notebook Python bien document√© int√©grant toutes ces √©tapes.

## Web Scraping and Interactive Dashboard

The project involves analyzing election polling data in groups of three by collecting information from assigned Wikipedia pages, cleaning and processing the data using Python (especially Pandas), and creating an interactive interface for users to explore the data. The interface should include visualizations, summary statistics, and manual data entry options, with libraries like Streamlit, Dash, or Tkinter recommended for a user-friendly design.

## Coffee Shop Analysis project
This project focuses on leveraging Python to analyze and visualize data for optimizing the performance of a coffee shop. Using the libraries **Matplotlib** and **Seaborn**, it involves exploring sales patterns through line plots, bar charts, scatter plots, box plots, and violin plots. The project also includes the creation of an advanced dashboard showcasing key insights, such as sales trends, product profitability, and the relationship between temperature and coffee sales. By combining these visualizations, the project provides actionable strategies to improve decision-making and business outcomes for the coffee shop.





